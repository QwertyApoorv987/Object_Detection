{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Collecting_Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QwertyApoorv987/Object_Detection/blob/main/Collecting_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_5nzefKl_pn",
        "outputId": "08ec8817-ddc0-41ee-b63e-5753f7de27bf"
      },
      "source": [
        "!pip install selenium\r\n",
        "!apt-get update \r\n",
        "!apt install chromium-chromedriver\r\n",
        "\r\n",
        "from selenium import webdriver\r\n",
        "chrome_options = webdriver.ChromeOptions()\r\n",
        "chrome_options.add_argument('--headless')\r\n",
        "chrome_options.add_argument('--no-sandbox')\r\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\r\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\r\n",
        "DRIVER_PATH =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 252 kB in 2s (122 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (87.0.4280.66-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: use options instead of chrome_options\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO0Z8q3ilq-g"
      },
      "source": [
        "import requests\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "from io import BytesIO\r\n",
        "import cv2\r\n",
        "import urllib.request\r\n",
        "import numpy as np\r\n",
        "search_term = [\"twoanimals\"] ###### change\r\n",
        "number_images = 15\r\n",
        "target_path = './images'\r\n",
        "\r\n",
        "\r\n",
        "# !zip -r mouseandcats.zip mouseandcats/ \r\n",
        "# files.download('mouseandcats.zip') \r\n",
        "\r\n",
        "# !zip -r monkeys.zip monkeys/ \r\n",
        "# files.download('monkeys.zip') \r\n",
        "\r\n",
        "# !zip -r dogsandmouse.zip dogsandmouse/ \r\n",
        "# files.download('dogsandmouse.zip')\r\n",
        "\r\n",
        "# !zip -r monkeysandcats.zip mouseandcats/ \r\n",
        "# files.download('monkeysandcats.zip')\r\n",
        "\r\n",
        "# !zip -r monkeysanddogs.zip mouseanddogs/ \r\n",
        "# files.download('monkeysanddogs.zip')\r\n",
        "\r\n",
        "# !zip -r monkeysandmouse.zip mouseandmouse/ \r\n",
        "# files.download('monkeysandmouse.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeiy57Nmi-tp"
      },
      "source": [
        "def url_to_image(url):\r\n",
        "\t# download the image, convert it to a NumPy array, and then read\r\n",
        "\t# it into OpenCV format\r\n",
        "\tresp = urllib.request.urlopen(url)\r\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\r\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\r\n",
        "\t# return the image\r\n",
        "\treturn image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2EYB0JLcyTN"
      },
      "source": [
        "def get_image_urls(query:str, max_links_to_fetch:int, wd:webdriver, sleep_between_interactions:int=1):\n",
        "    def scroll_to_end(wd):\n",
        "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(sleep_between_interactions)    \n",
        "    \n",
        "    # build the google query\n",
        "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
        "\n",
        "    # load the page\n",
        "    wd.get(search_url.format(q=query))\n",
        "\n",
        "    image_urls = set()\n",
        "    image_count = 0\n",
        "    results_start = 0\n",
        "    while image_count < max_links_to_fetch:\n",
        "        scroll_to_end(wd)\n",
        "\n",
        "        # get all image thumbnail results\n",
        "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
        "        number_results = len(thumbnail_results)\n",
        "        \n",
        "        print(f\"Found: {number_results} search results. Extracting links from {results_start}:{number_results}\")\n",
        "        \n",
        "        for img in thumbnail_results[results_start:number_results]:\n",
        "            # try to click every thumbnail such that we can get the real image behind it\n",
        "            try:\n",
        "                img.click()\n",
        "                time.sleep(sleep_between_interactions)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            # extract image urls    \n",
        "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n",
        "            for actual_image in actual_images:\n",
        "                if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\n",
        "                    image_urls.add(actual_image.get_attribute('src'))\n",
        "\n",
        "            image_count = len(image_urls)\n",
        "\n",
        "            if len(image_urls) >= max_links_to_fetch:\n",
        "                print(f\"Found: {len(image_urls)} image links, done!\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\n",
        "            time.sleep(30)\n",
        "            return\n",
        "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
        "            if load_more_button:\n",
        "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
        "\n",
        "        # move the result startpoint further down\n",
        "        results_start = len(thumbnail_results)\n",
        "\n",
        "    return image_urls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBTArMVAcyTU"
      },
      "source": [
        "# def persist_image(folder_path:str,url:str,fname:int):\n",
        "#   print(fname)\n",
        "#   #img = url_to_image(url)\n",
        "#   image = requests.get(url)\n",
        "#   image.raise_for_status()  #### 2 steps for compplete returning of object from the url\n",
        "#   img = Image.open(BytesIO(image.content)).convert('RGBA')\n",
        "#   #all_images.append(img)\n",
        "#   if len(str(fname))==3:\n",
        "#     with open(str(fname) + '.jpg', 'wb') as f:\n",
        "#       xyz = bytearray(image.content)\n",
        "#       f.write(xyz)\n",
        "#       fname = fname + 1\n",
        "#   if len(str(fname))==2:\n",
        "#     with open('0' + str(fname) + '.jpg', 'wb') as f:\n",
        "#       xyz = bytearray(image.content)\n",
        "#       f.write(xyz)\n",
        "#       fname = fname + 1\n",
        "#   if len(str(fname))==1:\n",
        "#     with open('00' + str(fname) + '.jpg', 'wb') as f:\n",
        "#       xyz = bytearray(image.content)\n",
        "#       f.write(xyz)\n",
        "#       fname = fname + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5kXdU_jcyTa"
      },
      "source": [
        "def search_and_download(search_term:str, wd, target_path,number_images):\n",
        "    target_folder = os.path.join(target_path,'_'.join(search_term.lower().split(' ')))\n",
        "\n",
        "    #if not os.path.exists(target_folder):\n",
        "    #    os.makedirs(target_folder)\n",
        "\n",
        "    with wd as wd:\n",
        "        res = get_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=0.5)\n",
        "        #print(res)\n",
        "\n",
        "    fname = 0   \n",
        "    for elem in res:\n",
        "      try:\n",
        "        image = requests.get(elem)\n",
        "        image.raise_for_status()  \n",
        "        img = Image.open(BytesIO(image.content)).convert('RGBA')\n",
        "        if len(str(fname))==3:\n",
        "          with open(str(fname) + '.jpg', 'wb') as f:\n",
        "            xyz = bytearray(image.content)\n",
        "            f.write(xyz)\n",
        "            fname = fname + 1\n",
        "        if len(str(fname))==2:\n",
        "          with open('0' + str(fname) + '.jpg', 'wb') as f:\n",
        "            xyz = bytearray(image.content)\n",
        "            f.write(xyz)\n",
        "            fname = fname + 1\n",
        "        if len(str(fname))==1:\n",
        "          with open('00' + str(fname) + '.jpg', 'wb') as f:\n",
        "            xyz = bytearray(image.content)\n",
        "            f.write(xyz)\n",
        "            fname = fname + 1\n",
        "      except Exception as e:\n",
        "        print(\"ERROR\")\n",
        "      #print(0)\n",
        "        #persist_image(target_folder,elem,i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk_ku_BDcyTe",
        "outputId": "c55b88c5-52d8-4ff8-800d-0b641bbc3937"
      },
      "source": [
        "import os \n",
        "import time\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "import hashlib\n",
        "i= 0\n",
        "!mkdir animals\n",
        "%cd animals\n",
        "for ele in search_term:\n",
        "    search_and_download(ele, wd, target_path, number_images)\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘animals’: File exists\n",
            "/content/animals\n",
            "Found: 100 search results. Extracting links from 0:100\n",
            "Found: 15 image links, done!\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3uvKj5rlCa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077c4871-7071-4c18-cd5d-84bbe8034c7a"
      },
      "source": [
        "from google.colab import files                     ############################## change ###################\r\n",
        "# #!zip -r mouseandcats.zip mouseandcats/ \r\n",
        "# #files.download('mouseandcats.zip') #### cat \r\n",
        "\r\n",
        "!zip -r animals.zip animals/ \r\n",
        "files.download('animals.zip') #### cat "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: animals/ (stored 0%)\n",
            "updating: animals/013.jpg (deflated 0%)\n",
            "updating: animals/006.jpg (deflated 0%)\n",
            "updating: animals/001.jpg (deflated 1%)\n",
            "updating: animals/008.jpg (deflated 0%)\n",
            "updating: animals/007.jpg (deflated 3%)\n",
            "updating: animals/010.jpg (deflated 0%)\n",
            "updating: animals/011.jpg (deflated 0%)\n",
            "updating: animals/003.jpg (deflated 2%)\n",
            "updating: animals/014.jpg (deflated 1%)\n",
            "updating: animals/005.jpg (deflated 1%)\n",
            "updating: animals/004.jpg (deflated 1%)\n",
            "updating: animals/000.jpg (deflated 2%)\n",
            "updating: animals/012.jpg (deflated 3%)\n",
            "updating: animals/002.jpg (deflated 3%)\n",
            "updating: animals/009.jpg (deflated 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e78f6f95-420b-459d-88f3-45fe43eaae3f\", \"animals.zip\", 2850843)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}